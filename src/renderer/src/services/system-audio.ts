// src/renderer/services/windowAudioCapture.ts
import { AUDIO_PROCESSING_CONFIG } from '@renderer/config/audio-processing'

interface AudioSegment {
  blob: Blob
  timestamp: number
  processed: boolean
}

export class WindowAudioCapture {
  private mediaRecorder: MediaRecorder | null = null
  private audioSegments: AudioSegment[] = []
  private readonly MAX_SEGMENTS = AUDIO_PROCESSING_CONFIG.MAX_AUDIO_SEGMENTS
  private stream: MediaStream | null = null

  async start() {
    console.log('ğŸ¥ Iniciando captura de Ã¡udio da janela...')
    this.stream = await navigator.mediaDevices.getDisplayMedia({
      audio: AUDIO_PROCESSING_CONFIG.SYSTEM_AUDIO_CONFIG,
      video: false
    })

    console.log('ğŸ¥ Captura de Ã¡udio da janela iniciada:', this.stream)

    this.mediaRecorder = new MediaRecorder(this.stream, {
      mimeType: AUDIO_PROCESSING_CONFIG.MIME_TYPE
    })
    this.audioSegments = []

    this.mediaRecorder.ondataavailable = (e) => {
      if (e.data.size > 0) {
        this.audioSegments.push({
          blob: e.data,
          timestamp: Date.now(),
          processed: false
        })
      }
    }

    // Iniciar gravaÃ§Ã£o contÃ­nua - vamos parar/reiniciar para coletar segmentos vÃ¡lidos
    this.mediaRecorder.start()
    console.log('ğŸ™ï¸ Captura de Ã¡udio da janela iniciada.')
  }

  async getAndClearRecentChunks(): Promise<Blob> {
    return new Promise((resolve) => {
      if (!this.mediaRecorder || this.mediaRecorder.state !== 'recording') {
        resolve(new Blob([], { type: 'audio/webm' }))
        return
      }

      // Parar a gravaÃ§Ã£o atual para obter um blob vÃ¡lido
      this.mediaRecorder.onstop = () => {
        // Coletar todos os chunks nÃ£o processados
        const recentChunks = this.audioSegments
          .filter((segment) => !segment.processed)
          .map((segment) => {
            segment.processed = true
            return segment.blob
          })

        const audioBlob = new Blob(recentChunks, { type: 'audio/webm' })

        // Limpeza periÃ³dica
        this.cleanupOldSegments()

        // Reiniciar a gravaÃ§Ã£o imediatamente
        if (this.stream && this.stream.active) {
          this.mediaRecorder = new MediaRecorder(this.stream, {
            mimeType: AUDIO_PROCESSING_CONFIG.MIME_TYPE
          })

          this.mediaRecorder.ondataavailable = (e) => {
            if (e.data.size > 0) {
              this.audioSegments.push({
                blob: e.data,
                timestamp: Date.now(),
                processed: false
              })
            }
          }

          this.mediaRecorder.start()
        }

        resolve(audioBlob)
      }

      this.mediaRecorder.stop()
    })
  }

  private cleanupOldSegments() {
    if (this.audioSegments.length > this.MAX_SEGMENTS) {
      // Manter apenas os Ãºltimos MAX_SEGMENTS
      this.audioSegments = this.audioSegments.slice(-this.MAX_SEGMENTS)
    }
  }

  getMemoryUsage(): number {
    return this.audioSegments.reduce((total, segment) => total + segment.blob.size, 0)
  }

  async stop(): Promise<Blob> {
    return new Promise((resolve) => {
      if (!this.mediaRecorder) return resolve(new Blob())

      this.mediaRecorder.onstop = () => {
        // Retornar todos os chunks nÃ£o processados
        const remainingChunks = this.audioSegments
          .filter((segment) => !segment.processed)
          .map((segment) => segment.blob)

        const audioBlob = new Blob(remainingChunks, { type: 'audio/webm' })

        // Limpar tudo
        this.audioSegments = []

        // Parar stream
        if (this.stream) {
          this.stream.getTracks().forEach((track) => track.stop())
          this.stream = null
        }

        console.log('ğŸ›‘ Captura de Ã¡udio da janela parada.')
        resolve(audioBlob)
      }

      this.mediaRecorder.stop()
    })
  }

  isRecording(): boolean {
    return this.mediaRecorder?.state === 'recording'
  }
}

export const windowAudioCapture = new WindowAudioCapture()
